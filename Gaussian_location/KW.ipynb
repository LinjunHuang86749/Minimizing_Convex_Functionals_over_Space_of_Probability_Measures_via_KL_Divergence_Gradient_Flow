{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JduICjZEGswc"
      },
      "outputs": [],
      "source": [
        "given_data_size = 5000\n",
        "total_trial_num = 10\n",
        "eta = 1e0\n",
        "t_max = 25\n",
        "set_seed = 114530"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l69eHbo4FD-d",
        "outputId": "41e23023-3715-451f-c45e-4550929c0621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting normflows\n",
            "  Downloading normflows-1.7.2.tar.gz (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from normflows) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from normflows) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->normflows) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->normflows) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->normflows) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->normflows) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->normflows) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->normflows) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->normflows) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->normflows) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->normflows) (1.3.0)\n",
            "Building wheels for collected packages: normflows\n",
            "  Building wheel for normflows (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for normflows: filename=normflows-1.7.2-py2.py3-none-any.whl size=86917 sha256=e5e36c7672cf185458d4b0e93672ab71ba0384976c7c0d7306a741cc8f0c9573\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/a4/89/3e09f53a561355c45eccfebeffc07a0e34d36a3f41e3ef68a3\n",
            "Successfully built normflows\n",
            "Installing collected packages: normflows\n",
            "Successfully installed normflows-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install normflows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SYGQ0L75A8_H"
      },
      "outputs": [],
      "source": [
        "# Import required packages\n",
        "import torch\n",
        "import numpy as np\n",
        "import normflows as nf\n",
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from IPython.display import clear_output\n",
        "import torch.nn.functional as F\n",
        "import torch.distributions as TD\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import torch.nn as nn\n",
        "import shutil\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enable_cuda = True\n",
        "device = torch.device('cuda' if torch.cuda.is_available() and enable_cuda else 'cpu')\n",
        "sampled_theta_m = nf.distributions.TwoMoons().to(device)\n",
        "\n",
        "cov_mx = torch.tensor([[1, 0.0], [0.0, 1.]], dtype=torch.double).to(device)"
      ],
      "metadata": {
        "id": "zlvz2xtd-ykY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_XN4Rb_RGe15"
      },
      "outputs": [],
      "source": [
        "def get_p1_bottom_faster(wgt, x, theta_list):\n",
        "  num_samples = theta_list.shape[0]\n",
        "  given_data_size = x.shape[0]\n",
        "\n",
        "  std_normal = TD.MultivariateNormal(\n",
        "            torch.zeros(num_samples, 2).to(device),\n",
        "            cov_mx.unsqueeze(0).repeat(num_samples, 1, 1),\n",
        "            validate_args=False)\n",
        "  x_data_rep = x.repeat(1,1,num_samples).reshape(given_data_size,num_samples,-1)\n",
        "  prob_mx = torch.exp(std_normal.log_prob(theta_list - x_data_rep))\n",
        "  wgt_rep = wgt.repeat(given_data_size, 1)\n",
        "  return torch.nanmean(prob_mx*wgt_rep, 1)*given_data_size\n",
        "\n",
        "\n",
        "def find_L_n_ver4(x, wgt, theta_list):\n",
        "  num_samples = theta_list.shape[0]\n",
        "  given_data_size = x.shape[0]\n",
        "  mu = theta_list\n",
        "  std_normal = TD.MultivariateNormal(\n",
        "            mu.to(device),\n",
        "            cov_mx.to(device).unsqueeze(0).repeat(num_samples, 1, 1).to(device),\n",
        "            validate_args=False)\n",
        "  x_data_rep = x.repeat(1,1,num_samples).reshape(given_data_size,num_samples,-1)\n",
        "  prob_mx = torch.exp(std_normal.log_prob(x_data_rep))\n",
        "  prob_mx_log_col_mean = torch.log(torch.sum(prob_mx*wgt.repeat(given_data_size,1), dim = 1))\n",
        "  return -torch.mean(prob_mx_log_col_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4l2N2dMNf70"
      },
      "outputs": [],
      "source": [
        "Ln_rho_k_list = np.zeros((total_trial_num, t_max))\n",
        "\n",
        "for trail_num in range(total_trial_num):\n",
        "\n",
        "  torch.manual_seed(set_seed + trail_num)\n",
        "\n",
        "  sampled_mean = sampled_theta_m.sample(given_data_size).to(device).to(torch.float64)\n",
        "  normal_temp = TD.MultivariateNormal(\n",
        "        sampled_mean.to(device),\n",
        "        cov_mx.to(device).unsqueeze(0).repeat(given_data_size, 1, 1).to(device),\n",
        "        validate_args=False)\n",
        "\n",
        "  given_data = normal_temp.sample().detach().to(device)\n",
        "\n",
        "  grid_size = 55\n",
        "  L = torch.max(given_data).item()\n",
        "  xx, yy = torch.meshgrid(torch.linspace(-L, L, grid_size), torch.linspace(-L, L, grid_size))\n",
        "  zz = torch.cat([xx.unsqueeze(2), yy.unsqueeze(2)], 2).view(-1, 2)\n",
        "  zz = zz.to(device)\n",
        "  num_samples = grid_size ** 2\n",
        "\n",
        "  mu = zz\n",
        "  wgt = torch.tensor([1/num_samples], dtype=torch.float64).repeat(num_samples).to(device)\n",
        "  L_n_loss_list = np.array([])\n",
        "\n",
        "  folder_name = 'trial' + str(trail_num)\n",
        "  for t in tqdm(range(t_max)):\n",
        "    num_samples = grid_size ** 2 # m\n",
        "    given_data_size = given_data.shape[0]\n",
        "\n",
        "    std_normal = TD.MultivariateNormal(\n",
        "              torch.zeros(num_samples, 2).to(device),\n",
        "              cov_mx.unsqueeze(0).repeat(num_samples, 1, 1),\n",
        "              validate_args=False)\n",
        "\n",
        "    x_data_rep = given_data.repeat(1,1,num_samples).reshape(given_data_size,num_samples,-1)\n",
        "\n",
        "    prob_mx_new = torch.transpose(torch.exp(std_normal.log_prob(mu - x_data_rep)), 0, 1)\n",
        "    new_bottom = get_p1_bottom_faster(wgt, given_data, mu).repeat(1,1,num_samples).reshape(num_samples,given_data_size)\n",
        "    wgt_update = torch.nanmean(prob_mx_new/new_bottom,1) - 1\n",
        "    wgt = wgt + eta*wgt_update*wgt\n",
        "    wgt = wgt/torch.sum(wgt)\n",
        "\n",
        "    L_n_loss = find_L_n_ver4(given_data, wgt, mu)\n",
        "    L_n_loss_list = np.append(L_n_loss_list, L_n_loss.to('cpu').data.numpy())\n",
        "\n",
        "    if t % 5 == 4:\n",
        "      print('trail:',trail_num, 'L_n :', L_n_loss.item() )\n",
        "\n",
        "  Ln_rho_k_list[trail_num,:] = L_n_loss_list\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}